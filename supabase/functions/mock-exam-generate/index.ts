import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

// Direct API Keys
const GEMINI_API_KEY = Deno.env.get("GEMINI_API_KEY");
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const ANTHROPIC_API_KEY = Deno.env.get("ANTHROPIC_API_KEY");
const COHERE_API_KEY = Deno.env.get("COHERE_API_KEY");
const ELEVENLABS_API_KEY = Deno.env.get("ELEVENLABS_API_KEY");

// ============================================
// ElevenLabs Korean Native Voice Presets (ë³µêµ¬)
// ============================================
// ê¸°ì¡´ì— ì‚¬ìš©í•˜ë˜ ì»¤ìŠ¤í…€ í•œêµ­ì–´ ë„¤ì´í‹°ë¸Œ ë³´ì´ìŠ¤ ID
const ELEVENLABS_VOICES = {
  female: "ksaI0TCD9BstzEzlxj4q",
  male: "WqVy7827vjE2r3jWvbnP",
} as const;

// TTS Presets for different use cases
const TTS_PRESETS = {
  exam: {
    voiceFemale: ELEVENLABS_VOICES.female,
    voiceMale: ELEVENLABS_VOICES.male,
    // ElevenLabsëŠ” ë³„ë„ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì§€ ì•Šìœ¼ë¯€ë¡œ ë¡œê·¸/ì„¤ëª…ìš©
    prompt: "TOPIK ì‹œí—˜ìš©: ëª…í™•í•˜ê³  ë˜ë ·í•œ ë°œìŒ, ì¤‘ê°„ ì†ë„",
  },
  learning: {
    voiceFemale: ELEVENLABS_VOICES.female,
    voiceMale: ELEVENLABS_VOICES.male,
    prompt: "í•™ìŠµìš©: ì²œì²œíˆ ë˜ë ·í•˜ê²Œ",
  },
  natural: {
    voiceFemale: ELEVENLABS_VOICES.female,
    voiceMale: ELEVENLABS_VOICES.male,
    prompt: "ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” í†¤",
  },
  formal: {
    voiceFemale: ELEVENLABS_VOICES.female,
    voiceMale: ELEVENLABS_VOICES.male,
    prompt: "ê²©ì‹ ìˆëŠ” í†¤",
  },
} as const;

// RAG Configuration
const RAG_CONFIG = {
  MATCH_THRESHOLD: 0.25,
  MATCH_COUNT: 20,
  RERANK_MODEL: 'rerank-v3.5',
  TOP_N: 8,
  EMBEDDING_MODEL: 'text-embedding-3-large',
  EMBEDDING_DIMENSIONS: 1536,
};

interface GenerateRequest {
  examType: "topik1" | "topik2";
  section: "listening" | "reading" | "writing";
  difficulty: "beginner" | "intermediate" | "advanced";
  topic?: string;
  questionCount: number;
  referenceDocUrl?: string;
  referenceDocContent?: string;
  useRag?: boolean;
  generateAudio?: boolean;
  ttsPreset?: keyof typeof TTS_PRESETS;
  stream?: boolean;
  // ë“£ê¸° ì„¸ë¶€ ì„¤ì •
  listeningQuestionType?: string;
  dialogueLength?: string;
  speakerCount?: string;
}

interface GeneratedQuestion {
  question_text: string;
  options: string[];
  correct_answer: number;
  explanation_ko: string;
  explanation_en: string;
  explanation_vi: string;
  part_number: number;
  question_number: number;
  grammar_points: string[];
  vocabulary: string[];
  difficulty: string;
  topic: string;
  listening_script?: string;
  question_audio_url?: string;
  question_image_url?: string;
  // [1-3ë²ˆ] ê·¸ë¦¼ ë¬¸ì œìš© - 4ê°œ ì´ë¯¸ì§€ URL
  option_images?: string[];
  // [1-3ë²ˆ] ê·¸ë¦¼ ë¬¸ì œìš© - 4ê°œ ì¥ë©´/ê·¸ë˜í”„ ì„¤ëª… (AI ì´ë¯¸ì§€ ìƒì„±ìš©)
  option_image_descriptions?: string[];
  // [1-3ë²ˆ] ê·¸ë¦¼ ë¬¸ì œ ìœ í˜•: "scene" (ì¥ë©´/í–‰ë™) ë˜ëŠ” "graph" (ê·¸ë˜í”„/ë„í‘œ)
  picture_type?: "scene" | "graph";
  // [21-50ë²ˆ] ì„¸íŠ¸í˜• ë¬¸ì œìš© - ê°™ì€ ì„¸íŠ¸ IDëŠ” ë™ì¼í•œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê³µìœ 
  set_id?: string;
  // [21-50ë²ˆ] ì„¸íŠ¸ ë‚´ ì§ˆë¬¸ ìœ í˜•: intent(ì˜ë„), detail(ì„¸ë¶€ë‚´ìš©), central_idea(ì¤‘ì‹¬ìƒê°), attitude(íƒœë„), speaking_style(ë§í•˜ëŠ” ë°©ì‹)
  question_type_in_set?: "intent" | "detail" | "central_idea" | "attitude" | "speaking_style";
}

// Generate embedding using OpenAI
async function generateEmbedding(text: string): Promise<number[]> {
  const response = await fetch('https://api.openai.com/v1/embeddings', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: RAG_CONFIG.EMBEDDING_MODEL,
      input: text,
      dimensions: RAG_CONFIG.EMBEDDING_DIMENSIONS,
    }),
  });

  if (!response.ok) {
    throw new Error(`OpenAI embedding error: ${response.status}`);
  }

  const data = await response.json();
  return data.data[0].embedding;
}

// Cohere Rerank
async function rerankResults(
  query: string,
  documents: any[],
  topN: number
): Promise<any[]> {
  if (documents.length === 0 || !COHERE_API_KEY) return documents.slice(0, topN);

  const response = await fetch('https://api.cohere.ai/v1/rerank', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${COHERE_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: RAG_CONFIG.RERANK_MODEL,
      query,
      documents: documents.map(d => d.content),
      top_n: Math.min(topN, documents.length),
      return_documents: false,
    }),
  });

  if (!response.ok) {
    console.error('Cohere rerank error, using fallback');
    return documents.slice(0, topN);
  }

  const data = await response.json();
  return data.results.map((result: any) => ({
    ...documents[result.index],
    rerank_score: result.relevance_score,
  }));
}

// RAG Search - Enhanced for listening scripts
async function ragSearch(
  query: string, 
  supabase: any, 
  section?: string,
  difficulty?: string
): Promise<string> {
  try {
    console.log('ğŸ” RAG search for:', query);
    
    // For listening section, create specialized queries for script patterns
    const queries: string[] = [query];
    
    if (section === 'listening') {
      // Add specialized listening script queries
      queries.push(
        'TOPIK ë“£ê¸° ëŒ€ë³¸ ìŠ¤í¬ë¦½íŠ¸ ëŒ€í™” íŒ¨í„´',
        'TOPIK listening script ë‚¨ì ì—¬ì ëŒ€í™”',
        'ë“£ê¸° ì‹œí—˜ ëŒ€í™”ë¬¸ ì˜ˆì‹œ ìŠ¤í¬ë¦½íŠ¸',
        `TOPIK ë“£ê¸° ${difficulty === 'beginner' ? 'ì´ˆê¸‰' : difficulty === 'advanced' ? 'ê³ ê¸‰' : 'ì¤‘ê¸‰'} ëŒ€í™”`
      );
    }
    
    // Collect all search results from multiple queries
    const allResults: any[] = [];
    const seenIds = new Set<string>();
    
    for (const q of queries) {
      const queryEmbedding = await generateEmbedding(q);
      
      const { data: searchResults, error } = await supabase.rpc(
        'search_knowledge',
        {
          query_embedding: `[${queryEmbedding.join(',')}]`,
          match_threshold: RAG_CONFIG.MATCH_THRESHOLD,
          match_count: section === 'listening' ? 30 : RAG_CONFIG.MATCH_COUNT, // More results for listening
        }
      );

      if (!error && searchResults?.length) {
        for (const result of searchResults) {
          if (!seenIds.has(result.id)) {
            seenIds.add(result.id);
            allResults.push(result);
          }
        }
      }
    }

    if (allResults.length === 0) {
      console.log('No RAG results found');
      return '';
    }

    console.log(`ğŸ“š Found ${allResults.length} total RAG results`);

    // For listening, prioritize script-related content
    let filteredResults = allResults;
    if (section === 'listening') {
      const scriptPatterns = ['ëŒ€ë³¸', 'ìŠ¤í¬ë¦½íŠ¸', 'script', 'ë‚¨ì:', 'ì—¬ì:', 'ëŒ€í™”', 'ë“£ê¸°'];
      const scored = allResults.map(r => {
        let score = r.similarity || 0;
        const content = r.content.toLowerCase();
        
        // Boost score for script-related content
        for (const pattern of scriptPatterns) {
          if (content.includes(pattern.toLowerCase())) {
            score += 0.1;
          }
        }
        
        // Extra boost for actual dialogue patterns
        if (content.includes('ë‚¨ì:') && content.includes('ì—¬ì:')) {
          score += 0.3;
        }
        if (content.match(/[ê°€-í£]+:\s*[ê°€-í£]/)) {
          score += 0.2;
        }
        
        return { ...r, boosted_score: score };
      });
      
      // Sort by boosted score
      scored.sort((a, b) => b.boosted_score - a.boosted_score);
      filteredResults = scored.slice(0, 40); // Take top 40 for reranking
    }

    // Rerank with listening-specific query
    const rerankQuery = section === 'listening' 
      ? `TOPIK ë“£ê¸° ëŒ€ë³¸ ìŠ¤í¬ë¦½íŠ¸ ëŒ€í™” ë‚¨ì ì—¬ì ${query}`
      : query;
    
    const topN = section === 'listening' ? 12 : RAG_CONFIG.TOP_N; // More context for listening
    const rerankedResults = await rerankResults(rerankQuery, filteredResults, topN);
    
    const context = rerankedResults.map((r: any, i: number) => 
      `[ì°¸ê³ ìë£Œ ${i + 1}] (${r.document_title || 'TOPIK ìë£Œ'})${r.boosted_score ? ` [ìŠ¤ì½”ì–´: ${r.boosted_score.toFixed(2)}]` : ''}\n${r.content}`
    ).join('\n\n---\n\n');

    console.log(`âœ… RAG found ${rerankedResults.length} relevant documents (listening enhanced: ${section === 'listening'})`);
    return context;
  } catch (error) {
    console.error('RAG search error:', error);
    return '';
  }
}

// Generate TTS audio using ElevenLabs (ë³µêµ¬)
// - Removes speaker labels like "ë‚¨ì:"/"ì—¬ì:" from spoken audio
// - If multiple speakers are detected, alternates voices per speaker and concatenates MP3 segments

async function synthesizeElevenLabsTTS(
  text: string,
  voiceId: string,
): Promise<Uint8Array> {
  if (!ELEVENLABS_API_KEY) throw new Error("ELEVENLABS_API_KEY not configured");

  const resp = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}?output_format=mp3_44100_128`,
    {
      method: "POST",
      headers: {
        "xi-api-key": ELEVENLABS_API_KEY,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        text,
        model_id: "eleven_v3",
        voice_settings: {
          // ê¸°ì¡´ ì„¸íŒ…ê°’ ë³µêµ¬
          stability: 1.0,
          similarity_boost: 0.9,
          style: 0.2,
          use_speaker_boost: true,
        },
      }),
    }
  );

  if (!resp.ok) {
    const t = await resp.text().catch(() => "");
    console.error("ElevenLabs TTS error:", resp.status, t);
    throw new Error(`ElevenLabs TTS failed (${resp.status})`);
  }

  const buf = await resp.arrayBuffer();
  return new Uint8Array(buf);
}

async function generateListeningAudio(
  script: string,
  questionNumber: number,
  examType: string,
  supabase: any,
  preset: keyof typeof TTS_PRESETS = "exam",
): Promise<string | null> {
  if (!script) return null;

  const presetCfg = TTS_PRESETS[preset] ?? TTS_PRESETS.exam;

  const detectSpeaker = (raw: string): { speakerKey: "male" | "female" | "other"; text: string } => {
    const line = raw.trim();
    const m = line.match(/^\s*(ë‚¨ì|ì—¬ì|ë‚¨ì„±|ì—¬ì„±|ë‚¨|ì—¬|A|B|C|D)\s*[:ï¼š]\s*(.*)$/i);
    if (!m) return { speakerKey: "other", text: line };

    const label = String(m[1]).toLowerCase();
    const text = String(m[2] ?? "").trim();

    if (["ì—¬ì", "ì—¬ì„±", "ì—¬"].includes(label)) return { speakerKey: "female", text };
    if (["ë‚¨ì", "ë‚¨ì„±", "ë‚¨"].includes(label)) return { speakerKey: "male", text };
    return { speakerKey: "other", text };
  };

  const stripLeadingId3 = (buf: ArrayBufferLike): Uint8Array => {
    const bytes = new Uint8Array(buf);
    if (bytes.length >= 10 && bytes[0] === 0x49 && bytes[1] === 0x44 && bytes[2] === 0x33) {
      const size =
        ((bytes[6] & 0x7f) << 21) |
        ((bytes[7] & 0x7f) << 14) |
        ((bytes[8] & 0x7f) << 7) |
        (bytes[9] & 0x7f);
      const start = Math.min(bytes.length, 10 + size);
      return bytes.slice(start);
    }
    return bytes;
  };

  const concatBytes = (parts: Uint8Array[]): Uint8Array => {
    const total = parts.reduce((acc, p) => acc + p.length, 0);
    const out = new Uint8Array(total);
    let offset = 0;
    for (const p of parts) {
      out.set(p, offset);
      offset += p.length;
    }
    return out;
  };

  try {
    console.log(`ğŸµ Generating ElevenLabs TTS audio for Q${questionNumber} preset=${preset}...`);

    const rawLines = script
      .split(/\r?\n/)
      .map((l) => l.trim())
      .filter(Boolean);

    const segments = rawLines.length
      ? rawLines.map(detectSpeaker).filter((s) => s.text)
      : [{ speakerKey: "other" as const, text: script.trim() }];

    const uniqueSpeakers = new Set(segments.map((s) => s.speakerKey));
    const isMultiSpeaker =
      uniqueSpeakers.size >= 2 && (uniqueSpeakers.has("male") || uniqueSpeakers.has("female"));

    let finalBytes: Uint8Array;

    if (isMultiSpeaker) {
      const audioParts: Uint8Array[] = [];

      for (let i = 0; i < segments.length; i++) {
        const seg = segments[i];
        const voiceId = seg.speakerKey === "male" ? presetCfg.voiceMale : presetCfg.voiceFemale;

        const t = seg.text.endsWith(".") || seg.text.endsWith("?") || seg.text.endsWith("!")
          ? seg.text
          : `${seg.text}.`;

        const bytes = await synthesizeElevenLabsTTS(t, voiceId);
        const withoutId3 = i === 0 ? bytes : stripLeadingId3(bytes.buffer);
        audioParts.push(withoutId3);
      }

      finalBytes = audioParts.length === 1 ? audioParts[0] : concatBytes(audioParts);
    } else {
      // Single voice: ê·¸ëŒ€ë¡œ í•©ì„±
      finalBytes = await synthesizeElevenLabsTTS(script.trim(), presetCfg.voiceFemale);
    }

    const fileName = `mock-exam/${examType}/listening_q${questionNumber}_${Date.now()}.mp3`;

    const { error: uploadError } = await supabase.storage
      .from("podcast-audio")
      .upload(fileName, finalBytes, {
        contentType: "audio/mpeg",
        upsert: true,
      });

    if (uploadError) {
      console.error("Audio upload error:", uploadError);
      return null;
    }

    const { data: urlData } = supabase.storage.from("podcast-audio").getPublicUrl(fileName);
    console.log(`âœ… ElevenLabs TTS audio generated for Q${questionNumber}`);
    return urlData.publicUrl;
  } catch (error) {
    console.error("ElevenLabs TTS generation error:", error);
    return null;
  }
}
/**
 * TOPIK II ë“£ê¸° ê·¸ë¦¼ ë¬¸ì œ ìœ í˜• (1-3ë²ˆ ë¬¸í•­)
 * 
 * ë¬¸í•­ 1-2: ì¥ë©´/í–‰ë™ ê·¸ë¦¼ (Scene Pictures)
 *   - ëŒ€í™” ë“£ê³  4ê°œ ê·¸ë¦¼ ì¤‘ ì•Œë§ì€ ê²ƒ ì„ íƒ
 *   - ë§Œí™”/ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼, í‘ë°± ë˜ëŠ” ì»¬ëŸ¬
 *   - ì¸ë¬¼ì˜ í–‰ë™, ìƒí™© ë¬˜ì‚¬
 * 
 * ë¬¸í•­ 3: ê·¸ë˜í”„/ë„í‘œ ê·¸ë¦¼ (Graph/Chart Pictures)
 *   - ë‹´í™”(ë‰´ìŠ¤, ê°•ì—°) ë“£ê³  ì•Œë§ì€ ê·¸ë˜í”„/ë„í‘œ ì„ íƒ
 *   - ì„  ê·¸ë˜í”„ + ì›í˜• ì°¨íŠ¸ ì¡°í•©
 *   - í†µê³„ ë°ì´í„°, ìˆ˜ì¹˜ ë¹„êµ
 */

// ê·¸ë¦¼ ë¬¸ì œ ìœ í˜• ì •ì˜
type PictureQuestionType = "scene" | "graph";

interface PictureQuestionConfig {
  type: PictureQuestionType;
  questionNumbers: number[];  // ë¬¸í•­ ë²ˆí˜¸
  description: string;
  imageStyle: string;
}

const TOPIK2_PICTURE_QUESTION_TYPES: PictureQuestionConfig[] = [
  {
    type: "scene",
    questionNumbers: [1, 2],
    description: "ì¥ë©´/í–‰ë™ ê·¸ë¦¼ - ëŒ€í™” ë“£ê³  ì•Œë§ì€ ê·¸ë¦¼ ì„ íƒ",
    imageStyle: "ë§Œí™”/ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼, êµìœ¡ìš© í‘ë°± ë˜ëŠ” ê°„ë‹¨í•œ ì»¬ëŸ¬"
  },
  {
    type: "graph",
    questionNumbers: [3],
    description: "ê·¸ë˜í”„/ë„í‘œ - ë‹´í™” ë“£ê³  ì•Œë§ì€ í†µê³„ ê·¸ë˜í”„ ì„ íƒ",
    imageStyle: "ì„  ê·¸ë˜í”„ + ì›í˜• ì°¨íŠ¸ ì¡°í•©, ê¹”ë”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ìŠ¤íƒ€ì¼"
  }
];

// Generate image for SCENE type picture questions (ë¬¸í•­ 1-2)
async function generateSceneImage(
  sceneDescription: string,
  questionNumber: number,
  optionNumber: number,
  examType: string,
  supabase: any,
): Promise<string | null> {
  const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY");
  if (!LOVABLE_API_KEY || !sceneDescription) return null;

  try {
    console.log(`ğŸ¨ [Scene Q${questionNumber}-${optionNumber}] ${sceneDescription.slice(0, 50)}...`);

    // TOPIK ìŠ¤íƒ€ì¼ ì¥ë©´ ê·¸ë¦¼ í”„ë¡¬í”„íŠ¸
    const imagePrompt = `Create a TOPIK Korean language test illustration.

Scene to illustrate: ${sceneDescription}

CRITICAL STYLE REQUIREMENTS:
1. Simple, clean LINE ART illustration (like official TOPIK test images)
2. Educational material style - suitable for language testing
3. NO text, NO speech bubbles, NO Korean/English words anywhere
4. Black and white or simple grayscale (like newspaper illustrations)
5. Clear, distinct actions that can be easily identified
6. 2D flat style, NOT 3D or photorealistic
7. Character proportions: simple, clear, cartoon-like
8. Background: minimal, just enough context for the scene
9. The illustration should look like it belongs in an official Korean language proficiency test

Reference style: Similar to TOPIK listening section picture dialogues - simple educational illustrations showing everyday situations.`;

    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash-image-preview",
        messages: [{ role: "user", content: imagePrompt }],
        modalities: ["image", "text"],
      }),
    });

    if (!response.ok) {
      console.error(`Scene image API error: ${response.status}`);
      return null;
    }

    const data = await response.json();
    const imageBase64 = data.choices?.[0]?.message?.images?.[0]?.image_url?.url;

    if (!imageBase64 || !imageBase64.startsWith("data:image/")) {
      console.error("No valid scene image in response");
      return null;
    }

    // Upload to storage
    const base64Data = imageBase64.split(",")[1];
    const binaryString = atob(base64Data);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }

    const mimeMatch = imageBase64.match(/data:image\/(\w+);/);
    const extension = mimeMatch ? mimeMatch[1] : "png";
    const fileName = `mock-exam/${examType}/scene_q${questionNumber}_opt${optionNumber}_${Date.now()}.${extension}`;

    const { error: uploadError } = await supabase.storage
      .from("podcast-audio")
      .upload(fileName, bytes.buffer, {
        contentType: `image/${extension}`,
        upsert: true,
      });

    if (uploadError) {
      console.error("Scene image upload error:", uploadError);
      return null;
    }

    const { data: urlData } = supabase.storage.from("podcast-audio").getPublicUrl(fileName);
    console.log(`âœ… Scene image Q${questionNumber}-${optionNumber} uploaded`);
    return urlData.publicUrl;
  } catch (error) {
    console.error("Scene image generation error:", error);
    return null;
  }
}

// Generate image for GRAPH type picture questions (ë¬¸í•­ 3)
async function generateGraphImage(
  graphDescription: string,
  questionNumber: number,
  optionNumber: number,
  examType: string,
  supabase: any,
): Promise<string | null> {
  const LOVABLE_API_KEY = Deno.env.get("LOVABLE_API_KEY");
  if (!LOVABLE_API_KEY || !graphDescription) return null;

  try {
    console.log(`ğŸ“Š [Graph Q${questionNumber}-${optionNumber}] ${graphDescription.slice(0, 50)}...`);

    // TOPIK ìŠ¤íƒ€ì¼ ê·¸ë˜í”„/ë„í‘œ í”„ë¡¬í”„íŠ¸
    const imagePrompt = `Create a TOPIK Korean language test GRAPH/CHART combination image.

Chart data to visualize: ${graphDescription}

CRITICAL REQUIREMENTS:
1. LAYOUT: The image must contain TWO charts side by side:
   - TOP or LEFT: A LINE GRAPH with title "ì„œë¹„ìŠ¤ ì´ìš©ì ìˆ˜" (Service Users)
   - BOTTOM or RIGHT: A PIE/DONUT CHART with title "ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ëŠ” ì´ìœ " (Reasons for Using Service)

2. LINE GRAPH specifications:
   - X-axis: Years (2020, 2021, 2022, 2023)
   - Y-axis: Numbers in ë§Œëª… (ten thousands) from 0-12
   - Show the trend described in the data
   - Korean labels: (ë§Œëª…) for y-axis, (ì—°ë„) for x-axis

3. PIE/DONUT CHART specifications:
   - Show percentage breakdown for reasons
   - Labels should be in Korean with percentages
   - Common reasons: ì‹ ì„ í•˜ê³  í’ˆì§ˆì´ ì¢‹ì•„ì„œ (Fresh/Good quality), ê°€ê²©ì´ í•©ë¦¬ì ì´ì–´ì„œ (Reasonable price), í¸ë¦¬í•´ì„œ (Convenient)

4. STYLE:
   - Clean, professional business chart style
   - Grayscale or minimal colors
   - Clear Korean text labels
   - Like official TOPIK II test materials

5. NO decorative elements, just clean data visualization

The graphs must clearly match the data described. Different options should show different trends or percentage distributions.`;

    const response = await fetch("https://ai.gateway.lovable.dev/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${LOVABLE_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "google/gemini-2.5-flash-image-preview",
        messages: [{ role: "user", content: imagePrompt }],
        modalities: ["image", "text"],
      }),
    });

    if (!response.ok) {
      console.error(`Graph image API error: ${response.status}`);
      return null;
    }

    const data = await response.json();
    const imageBase64 = data.choices?.[0]?.message?.images?.[0]?.image_url?.url;

    if (!imageBase64 || !imageBase64.startsWith("data:image/")) {
      console.error("No valid graph image in response");
      return null;
    }

    // Upload to storage
    const base64Data = imageBase64.split(",")[1];
    const binaryString = atob(base64Data);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }

    const mimeMatch = imageBase64.match(/data:image\/(\w+);/);
    const extension = mimeMatch ? mimeMatch[1] : "png";
    const fileName = `mock-exam/${examType}/graph_q${questionNumber}_opt${optionNumber}_${Date.now()}.${extension}`;

    const { error: uploadError } = await supabase.storage
      .from("podcast-audio")
      .upload(fileName, bytes.buffer, {
        contentType: `image/${extension}`,
        upsert: true,
      });

    if (uploadError) {
      console.error("Graph image upload error:", uploadError);
      return null;
    }

    const { data: urlData } = supabase.storage.from("podcast-audio").getPublicUrl(fileName);
    console.log(`âœ… Graph image Q${questionNumber}-${optionNumber} uploaded`);
    return urlData.publicUrl;
  } catch (error) {
    console.error("Graph image generation error:", error);
    return null;
  }
}

// Unified function to generate picture question images based on type
async function generatePictureQuestionImage(
  description: string,
  questionNumber: number,
  optionNumber: number,
  pictureType: PictureQuestionType,
  examType: string,
  supabase: any,
): Promise<string | null> {
  if (pictureType === "graph") {
    return generateGraphImage(description, questionNumber, optionNumber, examType, supabase);
  } else {
    return generateSceneImage(description, questionNumber, optionNumber, examType, supabase);
  }
}

// Build system prompt for Gemini
function buildSystemPrompt(params: GenerateRequest, ragContext: string): string {
  const levelInfo = {
    topik1: "TOPIK I (1-2ê¸‰, ì´ˆê¸‰-ì¤‘ê¸‰ ìˆ˜ì¤€)",
    topik2: "TOPIK II (3-6ê¸‰, ì¤‘ê¸‰-ê³ ê¸‰ ìˆ˜ì¤€)",
  };

  const sectionInfo = {
    listening: "ë“£ê¸° (Listening)",
    reading: "ì½ê¸° (Reading)",
    writing: "ì“°ê¸° (Writing)",
  };

  const difficultyInfo = {
    beginner: "ì´ˆê¸‰ (1-2ê¸‰ ìˆ˜ì¤€, ê¸°ë³¸ ì–´íœ˜ì™€ ê°„ë‹¨í•œ ë¬¸ì¥ êµ¬ì¡°)",
    intermediate: "ì¤‘ê¸‰ (3-4ê¸‰ ìˆ˜ì¤€, ë‹¤ì–‘í•œ ì£¼ì œì™€ ë³µì¡í•œ ë¬¸ì¥)",
    advanced: "ê³ ê¸‰ (5-6ê¸‰ ìˆ˜ì¤€, ì „ë¬¸ì  ë‚´ìš©ê³¼ ì¶”ìƒì  ê°œë…)",
  };

  let prompt = `ë‹¹ì‹ ì€ TOPIK(í•œêµ­ì–´ëŠ¥ë ¥ì‹œí—˜) ì „ë¬¸ ì¶œì œìœ„ì›ì…ë‹ˆë‹¤. 
ìµœê³  í’ˆì§ˆì˜ TOPIK ëª¨ì˜ê³ ì‚¬ ë¬¸ì œë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

## ì¶œì œ ì¡°ê±´
- ì‹œí—˜ ìœ í˜•: ${levelInfo[params.examType]}
- ì˜ì—­: ${sectionInfo[params.section]}
- ë‚œì´ë„: ${difficultyInfo[params.difficulty]}
- ìƒì„±í•  ë¬¸ì œ ìˆ˜: ${params.questionCount}ê°œ
${params.topic ? `- ì£¼ì œ/ë¬¸ë²•: ${params.topic}` : ''}

## ì¶œì œ ì›ì¹™
1. ì‹¤ì œ TOPIK ì‹œí—˜ í˜•ì‹ê³¼ 100% ë™ì¼í•œ ë¬¸ì œ êµ¬ì¡°
2. ì •í™•í•œ í•œêµ­ì–´ ë¬¸ë²•ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
3. ëª…í™•í•˜ê³  êµìœ¡ì ì¸ í•´ì„¤ (í•œêµ­ì–´, ì˜ì–´, ë² íŠ¸ë‚¨ì–´)
4. ê° ë³´ê¸°ëŠ” í•©ë¦¬ì ì´ê³  ë‚œì´ë„ì— ë§ëŠ” ì˜¤ë‹µ ì„ ì§€
5. ë¬¸ë²• í¬ì¸íŠ¸ì™€ í•µì‹¬ ì–´íœ˜ ëª…ì‹œ

## ë¬¸ì œ ìœ í˜• ê°€ì´ë“œ`;

  if (params.section === 'reading') {
    prompt += `
### ì½ê¸° ì˜ì—­ ë¬¸ì œ ìœ í˜•
- [1~4] ë¹ˆì¹¸ ì™„ì„± (ì–´íœ˜/ë¬¸ë²•)
- [5~9] ì£¼ì œ/ì œëª© ì°¾ê¸°
- [10~13] ê¸€ì˜ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒ ê³ ë¥´ê¸°
- [14~20] ë¹ˆì¹¸ ì™„ì„± (ë¬¸ë§¥)
- [21~30] ì§€ë¬¸ ë…í•´ í›„ ì§ˆë¬¸ ì‘ë‹µ

ê° ë¬¸ì œì—ëŠ” ë°˜ë“œì‹œ ì§€ë¬¸(ì½ê¸° í…ìŠ¤íŠ¸)ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.`;
  } else if (params.section === 'listening') {
    // ë“£ê¸° ì„¸ë¶€ ì„¤ì • íŒŒì‹±
    const questionType = params.listeningQuestionType || 'mixed';
    const dialogueLen = params.dialogueLength || 'auto';
    const speakers = params.speakerCount || 'auto';

    // ë¬¸ì œ ìœ í˜•ë³„ ì„¤ì •
    const questionTypeGuide: Record<string, { partRange: string; turns: string; description: string; isSet?: boolean }> = {
      "1-4": { partRange: "1~4", turns: "1-2í„´", description: "ì ì ˆí•œ ëŒ€ë‹µ ê³ ë¥´ê¸° (ê°„ë‹¨í•œ ì§ˆë¬¸-ì‘ë‹µ)" },
      "5-8": { partRange: "5~8", turns: "2-3í„´", description: "ê·¸ë¦¼ ë³´ê³  ì•Œë§ì€ ëŒ€í™” ê³ ë¥´ê¸°" },
      "9-12": { partRange: "9~12", turns: "3-4í„´", description: "ëŒ€í™”ì˜ ì¥ì†Œ/í™”ì œ/ëª©ì  íŒŒì•…" },
      "13-16": { partRange: "13~16", turns: "4-6í„´", description: "ì„¸ë¶€ ë‚´ìš© íŒŒì•…" },
      "17-20": { partRange: "17~20", turns: "5-8í„´", description: "í™”ìì˜ ì˜ë„/íƒœë„/í›„ì† í–‰ë™ íŒŒì•…" },
      "21-50-set": { partRange: "21~50", turns: "6-10í„´", description: "ì„¸íŠ¸í˜• ë¬¸ì œ (2ë¬¸í•­ 1ì„¸íŠ¸, ëŒ€í™”/ë‹´í™” ê³µìœ )", isSet: true },
    };

    const isSetQuestion = questionType === '21-50-set';

    // ëŒ€í™” ê¸¸ì´ ì„¤ì •
    const dialogueLengthGuide: Record<string, string> = {
      short: "ì§§ì€ ëŒ€í™” (1-3í„´)",
      medium: "ì¤‘ê°„ ëŒ€í™” (4-6í„´)",
      long: "ê¸´ ëŒ€í™” (7-10í„´)",
      auto: "ë¬¸ì œ ìœ í˜•ì— ë§ëŠ” ê¸¸ì´",
    };

    // í™”ì ìˆ˜ ì„¤ì •
    const speakerGuide: Record<string, string> = {
      "2": "ë‚¨ì-ì—¬ì 2ì¸ ëŒ€í™”",
      "3": "3ì¸ ëŒ€í™” (ë‚¨1-ì—¬1-ë‚¨2 ë˜ëŠ” ë‚¨1-ì—¬2)",
      "monologue": "1ì¸ ë‹´í™” (ê°•ì˜, ë‰´ìŠ¤, ì•ˆë‚´ë°©ì†¡ ë“±)",
      "auto": "ë¬¸ì œ ìœ í˜•ì— ë§ëŠ” í™”ì êµ¬ì„±",
    };

    prompt += `
### ë“£ê¸° ì˜ì—­ ë¬¸ì œ ìœ í˜•
${questionType === 'mixed' ? `
- [1~4] ì ì ˆí•œ ëŒ€ë‹µ ê³ ë¥´ê¸° (ê°„ë‹¨í•œ ì§ˆë¬¸-ì‘ë‹µ)
- [5~8] ê·¸ë¦¼ ë³´ê³  ì•Œë§ì€ ëŒ€í™” ê³ ë¥´ê¸°
- [9~12] ëŒ€í™”ì˜ ì¥ì†Œ/í™”ì œ/ëª©ì  íŒŒì•…
- [13~16] ì„¸ë¶€ ë‚´ìš© íŒŒì•… (ëŒ€í™” ë‚´ìš©ê³¼ ê°™ì€ ê²ƒ)
- [17~20] í™”ìì˜ ì˜ë„/íƒœë„/í›„ì† í–‰ë™ íŒŒì•…
- [21~50] ì„¸íŠ¸í˜• ë¬¸ì œ (2ë¬¸í•­ 1ì„¸íŠ¸)

ë‹¤ì–‘í•œ ìœ í˜•ì„ ê³¨ê³ ë£¨ ìƒì„±í•˜ì„¸ìš”.` : isSetQuestion ? `
âš ï¸ **ì„¸íŠ¸í˜• ë¬¸ì œ ìƒì„± (2ë¬¸í•­ 1ì„¸íŠ¸)**

TOPIK II ë“£ê¸° ì˜ì—­ 21~50ë²ˆì€ **ì„¸íŠ¸í˜• ë¬¸ì œ**ì…ë‹ˆë‹¤.
í•˜ë‚˜ì˜ ëŒ€í™” ë˜ëŠ” ë‹´í™”ë¥¼ ë“£ê³  2ê°œì˜ ë¬¸ì œì— ë‹µí•˜ëŠ” í˜•ì‹ì…ë‹ˆë‹¤.

**ì„¸íŠ¸í˜• ë¬¸ì œ êµ¬ì¡°:**
- ê° ì„¸íŠ¸ëŠ” ë°˜ë“œì‹œ 2ë¬¸ì œë¡œ êµ¬ì„±
- ê°™ì€ ì„¸íŠ¸ì˜ 2ë¬¸ì œëŠ” **ë™ì¼í•œ listening_script**ë¥¼ ê³µìœ 
- set_id í•„ë“œë¡œ ê°™ì€ ì„¸íŠ¸ì„ì„ í‘œì‹œ (ì˜ˆ: "set_1", "set_2")

**ì‹¤ì œ TOPIK II ì„¸íŠ¸í˜• ë¬¸ì œ ìœ í˜• (ì°¸ê³ ìš©):**

[23~24] ì¼ìƒ ëŒ€í™” ì„¸íŠ¸
- ì§ˆë¬¸1: "ë‚¨ìê°€ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ê³ ë¥´ì‹­ì‹œì˜¤." (ì˜ë„/í–‰ë™)
- ì§ˆë¬¸2: "ë“¤ì€ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤." (ì„¸ë¶€ ë‚´ìš©)
- ì˜ˆì‹œ ëŒ€í™”: ë°•ë¬¼ê´€ ì „ì‹œì‹¤ ì„¤ëª… ì˜¤ë¥˜ ìˆ˜ì • ìš”ì²­

[25~26] ì¸í„°ë·°/ëŒ€ë‹´ ì„¸íŠ¸
- ì§ˆë¬¸1: "ë‚¨ìì˜ ì¤‘ì‹¬ ìƒê°ìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤." (ì¤‘ì‹¬ ìƒê°)
- ì§ˆë¬¸2: "ë“¤ì€ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤." (ì„¸ë¶€ ë‚´ìš©)
- ì˜ˆì‹œ ëŒ€í™”: ê²½ì°°ì„œì¥ê³¼ì˜ ê²€ê±°ìœ¨ ì¸í„°ë·°

[47~48] í† ë¡ /ë…¼ì„¤ ì„¸íŠ¸ (ê³ ê¸‰)
- ì§ˆë¬¸1: "ë“¤ì€ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤." (ì„¸ë¶€ ë‚´ìš©)
- ì§ˆë¬¸2: "ë‚¨ìì˜ íƒœë„ë¡œ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤." (íƒœë„)
- ì˜ˆì‹œ ë‹´í™”: ì‚¬ì™¸ ì´ì‚¬ ì œë„ì— ëŒ€í•œ í† ë¡ 

[49~50] ê°•ì—°/ë°œí‘œ ì„¸íŠ¸ (ê³ ê¸‰)
- ì§ˆë¬¸1: "ë“¤ì€ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤." (ì„¸ë¶€ ë‚´ìš©)
- ì§ˆë¬¸2: "ë‚¨ìê°€ ë§í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤." (ë§í•˜ê¸° ë°©ì‹)
- ì˜ˆì‹œ ë‹´í™”: ëˆ„ë¦¬í˜¸ ìœ„ì„± ë°œì‚¬ ê´€ë ¨ ê°•ì—°` : `
âš ï¸ **ì§€ì •ëœ ë¬¸ì œ ìœ í˜•**: [${questionTypeGuide[questionType]?.partRange}ë²ˆ ìœ í˜•]
- ìœ í˜•: ${questionTypeGuide[questionType]?.description}
- ê¶Œì¥ ëŒ€í™” ê¸¸ì´: ${questionTypeGuide[questionType]?.turns}

ëª¨ë“  ë¬¸ì œë¥¼ ì´ ìœ í˜•ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.`}

### ğŸ§ ëŒ€í™” ì„¤ì •
- **ëŒ€í™” ê¸¸ì´**: ${dialogueLengthGuide[dialogueLen] || dialogueLengthGuide.auto}
- **í™”ì êµ¬ì„±**: ${speakerGuide[speakers] || speakerGuide.auto}

### ğŸµ ë“£ê¸° ìŠ¤í¬ë¦½íŠ¸ (listening_script) - ë§¤ìš° ì¤‘ìš”!

**ë°˜ë“œì‹œ ì°¸ê³ ìë£Œ(RAG)ì— ìˆëŠ” ì‹¤ì œ TOPIK ë“£ê¸° ëŒ€ë³¸ íŒ¨í„´ì„ ì°¸ê³ í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.**

ë“£ê¸° ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì›ì¹™:
1. **í™”ì í‘œì‹œ**: ë°˜ë“œì‹œ "ë‚¨ì:" / "ì—¬ì:" ë˜ëŠ” "ë‚¨:" / "ì—¬:" í˜•ì‹ ì‚¬ìš©${speakers === '3' ? ' (3ì¸: ë‚¨1, ì—¬1, ë‚¨2 ë“±)' : ''}${speakers === 'monologue' ? ' (1ì¸ ë‹´í™”: "í™”ì:" ë˜ëŠ” ë‚´ìš©ë§Œ)' : ''}
2. **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”**: ì‹¤ì œ í•œêµ­ì–´ ëŒ€í™”ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ (ì¶•ì•½, ì¡°ì‚¬ ìƒëµ ë“±)
3. **ëŒ€í™” ê¸¸ì´**: ${dialogueLen === 'short' ? '1-3í„´ì˜ ì§§ì€ ëŒ€í™”' : dialogueLen === 'medium' ? '4-6í„´ì˜ ì¤‘ê°„ ëŒ€í™”' : dialogueLen === 'long' ? '7-10í„´ì˜ ê¸´ ëŒ€í™”' : 'ë¬¸ì œ ìœ í˜•ì— ë§ëŠ” ì ì ˆí•œ ê¸¸ì´'}
4. **ë§¥ë½ ëª…í™•ì„±**: ìŠ¤í¬ë¦½íŠ¸ë§Œ ë³´ê³ ë„ ì •ë‹µì„ ë…¼ë¦¬ì ìœ¼ë¡œ ë„ì¶œí•  ìˆ˜ ìˆì–´ì•¼ í•¨
5. **ì˜¤ë‹µ ì„ ì§€ íƒ€ë‹¹ì„±**: ì˜¤ë‹µë„ ê·¸ëŸ´ë“¯í•´ì•¼ í•˜ì§€ë§Œ, ìŠ¤í¬ë¦½íŠ¸ì— ëª…í™•í•œ ê·¼ê±°ê°€ ì—†ì–´ì•¼ í•¨
${isSetQuestion ? `
6. **ì„¸íŠ¸ ë¬¸ì œ ì£¼ì˜ì‚¬í•­**: ê°™ì€ ì„¸íŠ¸ì˜ 2ë¬¸ì œëŠ” **ë™ì¼í•œ listening_script**ë¥¼ ê³µìœ 
7. ì²« ë²ˆì§¸ ë¬¸ì œì™€ ë‘ ë²ˆì§¸ ë¬¸ì œëŠ” ì„œë¡œ ë‹¤ë¥¸ ì§ˆë¬¸ ìœ í˜•ì´ì–´ì•¼ í•¨ (ì˜ˆ: ì˜ë„+ì„¸ë¶€ë‚´ìš©, ì¤‘ì‹¬ìƒê°+ì„¸ë¶€ë‚´ìš©)` : ''}

ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ (ìœ í˜•ë³„):

[1~4ë²ˆ ìœ í˜• - ì ì ˆí•œ ëŒ€ë‹µ]
"ì—¬ì: ì˜¤ëŠ˜ ì €ë…ì— ë­ í•  ê±°ì˜ˆìš”?"

[5~8ë²ˆ ìœ í˜• - ê·¸ë¦¼ ëŒ€í™”]
"ë‚¨ì: ì´ ì±… ì–´ë””ì— ë†“ì„ê¹Œìš”?\\nì—¬ì: ì € ì±…ìƒ ìœ„ì— ë†“ì•„ ì£¼ì„¸ìš”."

[9~12ë²ˆ ìœ í˜• - ì¥ì†Œ/í™”ì œ]
"ì—¬ì: ì–´ì„œ ì˜¤ì„¸ìš”. ë­˜ ì°¾ìœ¼ì„¸ìš”?\\në‚¨ì: ê°ê¸°ì•½ ì¢€ ì£¼ì„¸ìš”.\\nì—¬ì: ì–´ë–¤ ì¦ìƒì´ ìˆìœ¼ì„¸ìš”?\\në‚¨ì: ê¸°ì¹¨ì´ ë§ì´ ë‚˜ê³  ì—´ë„ ì¢€ ìˆì–´ìš”."

[13~16ë²ˆ ìœ í˜• - ì„¸ë¶€ ë‚´ìš©]
"ë‚¨ì: ì´ë²ˆ ì£¼ë§ì— ì‚°ì— ê°ˆ ê±´ë°, ê°™ì´ ê°ˆë˜?\\nì—¬ì: ì¢‹ì•„. ê·¸ëŸ°ë° ë‚ ì”¨ê°€ ê´œì°®ì„ê¹Œ?\\në‚¨ì: ì¼ê¸°ì˜ˆë³´ ë´¤ëŠ”ë° ë§‘ëŒ€. ì•„ì¹¨ 8ì‹œì— ì¶œë°œí•˜ì.\\nì—¬ì: ì•Œì•˜ì–´. ë„ì‹œë½ì€ ë‚´ê°€ ì¤€ë¹„í• ê²Œ."
${isSetQuestion ? `
[21~50ë²ˆ ìœ í˜• - ì„¸íŠ¸í˜• ë‹´í™”/ëŒ€í™”]
"ë‚¨ì: ë°©ê¸ˆ 3ì¸µ ìƒì„¤ ì „ì‹œê´€ì—ì„œ ê´€ëŒí•˜ê³  ë‚´ë ¤ì™”ëŠ”ë°ìš”. ì „ì‹œê´€ì— ì¨ ë†“ì€ ì„¤ëª… ë‚´ìš©ì— ì˜ëª»ëœ ê²Œ ìˆì–´ì„œìš”.\\nì—¬ì: ì£„ì†¡í•©ë‹ˆë‹¤. ë­ê°€ ì˜ëª»ë˜ì–´ ìˆë‚˜ìš”?\\në‚¨ì: ì²« ë²ˆì§¸ ì „ì‹œì‹¤ì„ ì†Œê°œí•˜ëŠ” ì˜ì–´ ì„¤ëª… ì¤‘ì— í‹€ë¦° ë‹¨ì–´ê°€ í•˜ë‚˜ ìˆë”ë¼ê³ ìš”. ë°•ë¬¼ê´€ì— ì™¸êµ­ì¸ë„ ë§ë˜ë° ë¹¨ë¦¬ ê³ ì³ ì£¼ì‹œë©´ ì¢‹ê² ì–´ìš”.\\nì—¬ì: ë§ì”€í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ë°”ë¡œ ì˜¬ë¼ê°€ì„œ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤."
` : ''}
[ë‹´í™”í˜• - ê°•ì—°/ë‰´ìŠ¤]
"ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ê°•ì˜ì—ì„œëŠ” í•œêµ­ì˜ ì „í†µ ìŒì‹ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. í•œêµ­ ìŒì‹ì€ ë°œíš¨ ì‹í’ˆì´ ë§ì€ ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤..."

question_textì—ëŠ” ì§ˆë¬¸ë§Œ ë„£ìœ¼ì„¸ìš”.
- ì¢‹ì€ ì˜ˆ: "ë‚¨ìëŠ” ì™œ ê°ê¸°ì•½ì„ ì‚¬ëŸ¬ ì™”ìŠµë‹ˆê¹Œ?"
- ë‚˜ìœ ì˜ˆ: "(ëŒ€í™”ë¥¼ ë“£ê³ ) ë‚¨ìëŠ”..." (ìŠ¤í¬ë¦½íŠ¸ëŠ” listening_scriptì—)`;
  }

  if (ragContext) {
    prompt += `\n\n## ğŸ“š ì°¸ê³  ìë£Œ (RAG ê²€ìƒ‰ ê²°ê³¼)
ë‹¤ìŒ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ë¬¸ì œë¥¼ ì¶œì œí•˜ì„¸ìš”. ì´ ìë£ŒëŠ” ì‹¤ì œ TOPIK ê¸°ì¶œë¬¸ì œ, êµì¬, ì–´íœ˜ ëª©ë¡ ë“±ì…ë‹ˆë‹¤:

${ragContext}

ìœ„ ì°¸ê³  ìë£Œì˜ ì–´íœ˜, ë¬¸ë²•, ë¬¸ì¥ íŒ¨í„´ì„ í™œìš©í•˜ì—¬ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ì˜ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.`;

    if (params.section === 'listening') {
      prompt += `

### âš ï¸ ë“£ê¸° ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹œ ì¤‘ìš” ì§€ì¹¨
1. **ìœ„ ì°¸ê³ ìë£Œì—ì„œ ì‹¤ì œ TOPIK ë“£ê¸° ëŒ€ë³¸ íŒ¨í„´ì„ ë¶„ì„í•˜ì„¸ìš”**
2. ëŒ€í™”ì˜ íë¦„, í™”ì êµëŒ€ íŒ¨í„´, í‘œí˜„ ë°©ì‹ì„ ì°¸ê³ í•˜ì„¸ìš”
3. ì°¸ê³ ìë£Œì— ìˆëŠ” ëŒ€í™” êµ¬ì¡°ë¥¼ ëª¨ë°©í•˜ë˜, ìƒˆë¡œìš´ ìƒí™©ìœ¼ë¡œ ë³€í˜•í•˜ì„¸ìš”
4. ì •ë‹µì´ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ëª…í™•íˆ ë„ì¶œë˜ë„ë¡ ì‘ì„±í•˜ì„¸ìš”
5. ì˜¤ë‹µ ì„ ì§€ëŠ” ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ ìŠ¤í¬ë¦½íŠ¸ì™€ ë§ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤`;
    }
  }

  if (params.referenceDocContent) {
    prompt += `\n\n## ğŸ“„ ì—…ë¡œë“œëœ ë ˆí¼ëŸ°ìŠ¤ ë¬¸ì„œ
ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œë¥¼ ìƒì„±/ë³€í˜•í•˜ì„¸ìš”:

${params.referenceDocContent}

ì´ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ:
1. ë¬¸ì œ í˜•ì‹ê³¼ ìŠ¤íƒ€ì¼ì„ ìœ ì§€
2. ì§€ì •ëœ ë‚œì´ë„(${params.difficulty})ì— ë§ê²Œ ë³€í˜•
3. ìƒˆë¡œìš´ ìƒí™©/ë§¥ë½ìœ¼ë¡œ ì‘ìš©
4. ìƒì„¸í•œ í•´ì„¤ ì¶”ê°€`;
  }

  // ì„¸íŠ¸í˜• ë¬¸ì œ ì—¬ë¶€ í™•ì¸
  const isSetQuestion = params.listeningQuestionType === '21-50-set';

prompt += `

## ğŸ“ í•´ì„¤ ì‘ì„± ê°€ì´ë“œ (ë§¤ìš° ì¤‘ìš”!)

### í•œêµ­ì–´ í•´ì„¤ (explanation_ko) - ë°˜ë“œì‹œ 200ì ì´ìƒ!

í•œêµ­ì–´ í•´ì„¤ì€ ë‹¤ìŒ êµ¬ì¡°ë¡œ **ìƒì„¸í•˜ê²Œ** ì‘ì„±í•˜ì„¸ìš”:

**í•„ìˆ˜ í¬í•¨ ìš”ì†Œ (6ê°€ì§€):**
1. **ë¬¸ì œ ìœ í˜• ì„¤ëª…**: "ì´ ë¬¸ì œëŠ” ~ì„/ë¥¼ ë¬»ëŠ” ë¬¸ì œì…ë‹ˆë‹¤."
2. **ì •ë‹µ ë¶„ì„**: "ì •ë‹µì€ â‘ ë²ˆì…ë‹ˆë‹¤. [ì •ë‹µì´ ë§ëŠ” ì´ìœ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]"
3. **ì˜¤ë‹µ ë¶„ì„**: ë‚˜ë¨¸ì§€ 3ê°œ ì„ ì§€ê°€ ì™œ í‹€ë¦°ì§€ ê°ê° ì„¤ëª…
4. **í•µì‹¬ ë¬¸ë²•/ì–´íœ˜**: ë¬¸ì œì— ë‚˜ì˜¨ í•µì‹¬ ë¬¸ë²•ì´ë‚˜ ì–´íœ˜ì˜ ì˜ë¯¸ì™€ ì‚¬ìš©ë²• ì„¤ëª…
5. **ì˜ˆë¬¸ ì œì‹œ**: ê´€ë ¨ ë¬¸ë²•/ì–´íœ˜ë¥¼ ì‚¬ìš©í•œ ì¶”ê°€ ì˜ˆë¬¸ 1-2ê°œ
6. **í•™ìŠµ íŒ**: ìœ ì‚¬ ë¬¸ì œë¥¼ í’€ ë•Œ ë„ì›€ì´ ë˜ëŠ” íŒ

**í•œêµ­ì–´ í•´ì„¤ ì˜ˆì‹œ (280ì):**
\`\`\`
ì´ ë¬¸ì œëŠ” ì¥ì†Œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¡°ì‚¬ 'ì—'ì™€ 'ì—ì„œ'ì˜ ì°¨ì´ë¥¼ ë¬»ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.

ì •ë‹µì€ â‘¢ë²ˆ 'ì—ì„œ'ì…ë‹ˆë‹¤. 'ì—ì„œ'ëŠ” ë™ì‘ì´ ì¼ì–´ë‚˜ëŠ” ì¥ì†Œë¥¼ ë‚˜íƒ€ë‚¼ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. "ë„ì„œê´€ì—ì„œ ì±…ì„ ì½ë‹¤"ì²˜ëŸ¼ 'ì½ë‹¤'ë¼ëŠ” ë™ì‘ì´ ì¼ì–´ë‚˜ëŠ” ê³³ì´ë¯€ë¡œ 'ì—ì„œ'ê°€ ì ì ˆí•©ë‹ˆë‹¤.

ì˜¤ë‹µ ë¶„ì„:
â‘  'ì—'ëŠ” ì¡´ì¬/ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ëƒ„ (ë„ì„œê´€ì— ìˆë‹¤)
â‘¡ 'ìœ¼ë¡œ'ëŠ” ë°©í–¥/ë„êµ¬ë¥¼ ë‚˜íƒ€ëƒ„ (ë²„ìŠ¤ë¡œ ê°€ë‹¤)
â‘£ 'ê¹Œì§€'ëŠ” ë„ì°©ì ì„ ë‚˜íƒ€ëƒ„ (í•™êµê¹Œì§€ ê±¸ì–´ê°€ë‹¤)

ğŸ’¡ í•™ìŠµ íŒ: '~í•˜ë‹¤' ë™ì‚¬ ì•ì—ëŠ” 'ì—ì„œ', 'ìˆë‹¤/ì—†ë‹¤' ì•ì—ëŠ” 'ì—'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!
ì¶”ê°€ ì˜ˆë¬¸: "ì¹´í˜ì—ì„œ ì»¤í”¼ë¥¼ ë§ˆì‹œë‹¤" / "ì§‘ì— í…”ë ˆë¹„ì „ì´ ìˆë‹¤"
\`\`\`

### ì˜ì–´/ë² íŠ¸ë‚¨ì–´ í•´ì„¤ - í•´ë‹¹ ì–¸ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­

explanation_en, explanation_viëŠ” í•œêµ­ì–´ í•´ì„¤ì„ ì •í™•íˆ ë²ˆì—­í•˜ë˜, í•´ë‹¹ ì–¸ì–´ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”.

## ì¶œë ¥ í˜•ì‹
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "questions": [
    {
      "question_text": "ë¬¸ì œ í…ìŠ¤íŠ¸ (ì½ê¸°: ì§€ë¬¸+ì§ˆë¬¸, ë“£ê¸°: ì§ˆë¬¸ë§Œ)",
      "options": ["â‘  ì„ ì§€1", "â‘¡ ì„ ì§€2", "â‘¢ ì„ ì§€3", "â‘£ ì„ ì§€4"],
      "correct_answer": 1-4 ì¤‘ ì •ë‹µ ë²ˆí˜¸,
      "explanation_ko": "200ì ì´ìƒì˜ ìƒì„¸í•œ í•œêµ­ì–´ í•´ì„¤ (ìœ„ ê°€ì´ë“œ ì°¸ê³ )",
      "explanation_en": "Detailed English explanation (translation of Korean)",
      "explanation_vi": "Giáº£i thÃ­ch chi tiáº¿t báº±ng tiáº¿ng Viá»‡t (dá»‹ch tá»« tiáº¿ng HÃ n)",
      "part_number": ë¬¸ì œ íŒŒíŠ¸ ë²ˆí˜¸,
      "question_number": ë¬¸ì œ ë²ˆí˜¸,
      "grammar_points": ["ë¬¸ë²• í¬ì¸íŠ¸1", "ë¬¸ë²• í¬ì¸íŠ¸2"],
      "vocabulary": ["ì–´íœ˜1 (ëœ»)", "ì–´íœ˜2 (ëœ»)"],
      "difficulty": "${params.difficulty}",
      "topic": "${params.topic || 'ì¼ë°˜'}"${params.section === 'listening' ? `,
      "listening_script": "ë‚¨ì: ...\\nì—¬ì: ..."${isSetQuestion ? `,
      "set_id": "set_1 ë˜ëŠ” set_2 ë“± (ê°™ì€ ì„¸íŠ¸ëŠ” ê°™ì€ ID)",
      "question_type_in_set": "intent/detail/attitude/speaking_style ì¤‘ í•˜ë‚˜"` : ''}${params.listeningQuestionType === '5-8' ? `,
      "picture_type": "scene ë˜ëŠ” graph",
      "option_image_descriptions": [
        "ë³´ê¸° â‘  ì„¤ëª…",
        "ë³´ê¸° â‘¡ ì„¤ëª…",
        "ë³´ê¸° â‘¢ ì„¤ëª…",
        "ë³´ê¸° â‘£ ì„¤ëª…"
      ]` : ''}` : ''}
    }
  ]
}

${isSetQuestion ? `
âš ï¸ [21~50ë²ˆ ì„¸íŠ¸í˜• ë¬¸ì œ] í•„ìˆ˜ ì§€ì¹¨ - TOPIK II ì‹¤ì œ ì‹œí—˜ í˜•ì‹ ì¤€ìˆ˜!

## ğŸ“Œ ì„¸íŠ¸í˜• ë¬¸ì œ êµ¬ì¡°

ì„¸íŠ¸í˜• ë¬¸ì œëŠ” **2ë¬¸í•­ì´ 1ì„¸íŠ¸**ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
ê°™ì€ ì„¸íŠ¸ì˜ ë¬¸ì œëŠ” **ë™ì¼í•œ listening_script**ì™€ **ë™ì¼í•œ set_id**ë¥¼ ê³µìœ í•©ë‹ˆë‹¤.

### ì§ˆë¬¸ ìœ í˜• (question_type_in_set)

1. **intent** - ì˜ë„/í–‰ë™ íŒŒì•…
   - "ë‚¨ìê°€ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ê³ ë¥´ì‹­ì‹œì˜¤."
   - "ë‚¨ìê°€ ì—¬ìì—ê²Œ ë¶€íƒí•œ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤."
   - "ì´ ëŒ€í™”ì—ì„œ ë‚¨ìê°€ í•˜ë ¤ëŠ” ë§ì„ ê³ ë¥´ì‹­ì‹œì˜¤."

2. **detail** - ì„¸ë¶€ ë‚´ìš© íŒŒì•…
   - "ë“¤ì€ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤."
   - "ë“¤ì€ ë‚´ìš©ê³¼ ë‹¤ë¥¸ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤."

3. **central_idea** - ì¤‘ì‹¬ ìƒê°
   - "ë‚¨ìì˜ ì¤‘ì‹¬ ìƒê°ìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤."
   - "ì—¬ìì˜ ì£¼ì¥ìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤."

4. **attitude** - íƒœë„ íŒŒì•…
   - "ë‚¨ìì˜ íƒœë„ë¡œ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤."
   - íƒœë„ ë³´ê¸° ì˜ˆì‹œ: 
     - "â‘  ì œë„ì˜ í•„ìš”ì„±ê³¼ ì˜ì˜ë¥¼ ê°•ì¡°í•˜ê³  ìˆë‹¤."
     - "â‘¡ ì œë„ì˜ ì§€ë‚˜ì¹œ í™•ëŒ€ ì ìš©ì„ ê²½ê³„í•˜ê³  ìˆë‹¤."
     - "â‘¢ ì œë„ì˜ í•œê³„ë¥¼ ì§€ì í•˜ë©° ê°œì„ ì±…ì„ ì´‰êµ¬í•˜ê³  ìˆë‹¤."
     - "â‘£ ì œë„ì˜ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ë©° ì‚¬íšŒì  ê´€ì‹¬ì„ í˜¸ì†Œí•˜ê³  ìˆë‹¤."

5. **speaking_style** - ë§í•˜ëŠ” ë°©ì‹
   - "ë‚¨ìê°€ ë§í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤."
   - ë°©ì‹ ë³´ê¸° ì˜ˆì‹œ:
     - "â‘  ë°œì‚¬ ì‹œê°ì´ ì •í•´ì§„ ë°°ê²½ì„ ê³¼í•™ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ìˆë‹¤."
     - "â‘¡ ìš°ì£¼ì„  ë°œì‚¬ì˜ ê³¼í•™ì‚¬ì  ì˜ë¯¸ë¥¼ ìƒˆë¡­ê²Œ ì •ì˜í•˜ê³  ìˆë‹¤."
     - "â‘¢ ìœ„ì„±ì´ ìš°ì£¼ì—ì„œ ì¼ìœ¼í‚¬ ìˆ˜ ìˆëŠ” ë¬¸ì œë¥¼ ì˜ˆì¸¡í•˜ê³  ìˆë‹¤."
     - "â‘£ ì²œë¬¸í•™ì  ì§€ì‹ì„ í† ëŒ€ë¡œ ë¬¸ì œ í•´ê²° ë°©ë²•ì„ ì œì‹œí•˜ê³  ìˆë‹¤."

### ì„¸íŠ¸ ì¡°í•© íŒ¨í„´ (ì°¸ê³ )

- **[23~24í˜•]**: intent + detail (ì¼ìƒ ëŒ€í™”)
- **[25~26í˜•]**: central_idea + detail (ì¸í„°ë·°/ëŒ€ë‹´)
- **[47~48í˜•]**: detail + attitude (í† ë¡ /ë…¼ì„¤)
- **[49~50í˜•]**: detail + speaking_style (ê°•ì—°/ë°œí‘œ)

### ì˜ˆì‹œ ì¶œë ¥ (4ë¬¸ì œ = 2ì„¸íŠ¸)

\`\`\`json
{
  "questions": [
    {
      "question_number": 23,
      "set_id": "set_1",
      "question_type_in_set": "intent",
      "question_text": "ë‚¨ìê°€ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ê³ ë¥´ì‹­ì‹œì˜¤.",
      "listening_script": "ë‚¨ì: ë°©ê¸ˆ 3ì¸µ ìƒì„¤ ì „ì‹œê´€ì—ì„œ ê´€ëŒí•˜ê³  ë‚´ë ¤ì™”ëŠ”ë°ìš”...",
      "options": ["â‘  ë°•ë¬¼ê´€ ë‹¨ì²´ ê´€ëŒì„ ì˜ˆì•½í•˜ê³  ìˆë‹¤.", "â‘¡ ë°•ë¬¼ê´€ ê´€ëŒ ì‹œê°„ì— ëŒ€í•´ ë¬¸ì˜í•˜ê³  ìˆë‹¤.", "â‘¢ ìƒì„¤ ì „ì‹œíšŒê°€ ì—´ë¦¬ëŠ” ì¥ì†Œë¥¼ í™•ì¸í•˜ê³  ìˆë‹¤.", "â‘£ ì „ì‹œì‹¤ì˜ ì„¤ëª…ì„ ìˆ˜ì •í•´ ë‹¬ë¼ê³  ìš”ì²­í•˜ê³  ìˆë‹¤."],
      "correct_answer": 4
    },
    {
      "question_number": 24,
      "set_id": "set_1",
      "question_type_in_set": "detail",
      "question_text": "ë“¤ì€ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤.",
      "listening_script": "ë‚¨ì: ë°©ê¸ˆ 3ì¸µ ìƒì„¤ ì „ì‹œê´€ì—ì„œ ê´€ëŒí•˜ê³  ë‚´ë ¤ì™”ëŠ”ë°ìš”...",
      "options": ["â‘  ì—¬ìëŠ” ì§€ê¸ˆ ë°•ë¬¼ê´€ 3ì¸µì— ìˆë‹¤.", "â‘¡ ë‚¨ìëŠ” ë°•ë¬¼ê´€ì—ì„œ ìƒì„¤ ì „ì‹œíšŒë¥¼ ê´€ëŒí–ˆë‹¤.", "â‘¢ ì´ ë°•ë¬¼ê´€ì—ëŠ” ì „ì‹œì‹¤ì— ì˜ì–´ ì„¤ëª…ì´ ì—†ë‹¤.", "â‘£ ì´ ë°•ë¬¼ê´€ì—ëŠ” ì™¸êµ­ì¸ë“¤ì´ ë§ì´ ì˜¤ì§€ ì•ŠëŠ”ë‹¤."],
      "correct_answer": 2
    },
    {
      "question_number": 25,
      "set_id": "set_2",
      "question_type_in_set": "central_idea",
      "question_text": "ë‚¨ìì˜ ì¤‘ì‹¬ ìƒê°ìœ¼ë¡œ ê°€ì¥ ì•Œë§ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤.",
      "listening_script": "ì—¬ì: ì„œì¥ë‹˜, ì¸ì£¼ê²½ì°°ì„œê°€ ì‘ë…„ì— ì´ì–´...",
      "options": ["â‘  ì‹¤ì œ ìƒí™©ì„ ê°€ì •í•œ ë°˜ë³µ í›ˆë ¨ì´ ì¤‘ìš”í•˜ë‹¤.", ...],
      "correct_answer": 1
    },
    {
      "question_number": 26,
      "set_id": "set_2",
      "question_type_in_set": "detail",
      "question_text": "ë“¤ì€ ë‚´ìš©ê³¼ ê°™ì€ ê²ƒì„ ê³ ë¥´ì‹­ì‹œì˜¤.",
      "listening_script": "ì—¬ì: ì„œì¥ë‹˜, ì¸ì£¼ê²½ì°°ì„œê°€ ì‘ë…„ì— ì´ì–´...",
      "options": ["â‘  ì´ ê²½ì°°ì„œê°€ ìˆëŠ” ì§€ì—­ì€ ì‚¬ê±´ì´ ìì£¼ ë°œìƒí•œë‹¤.", ...],
      "correct_answer": 1
    }
  ]
}
\`\`\`

## âš ï¸ í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­

1. **2ë¬¸í•­ 1ì„¸íŠ¸**: ê°™ì€ set_idë¥¼ ê°€ì§„ ë¬¸ì œëŠ” ë°˜ë“œì‹œ 2ê°œì”©
2. **ìŠ¤í¬ë¦½íŠ¸ ê³µìœ **: ê°™ì€ ì„¸íŠ¸ì˜ 2ë¬¸ì œëŠ” **ì™„ì „íˆ ë™ì¼í•œ listening_script**
3. **ì§ˆë¬¸ ë‹¤ì–‘ì„±**: ê°™ì€ ì„¸íŠ¸ ë‚´ì—ì„œ ì§ˆë¬¸ ìœ í˜•ì´ ë‹¬ë¼ì•¼ í•¨ (intent+detail ë“±)
4. **ë¬¸ì œ ìˆ˜ ë§ì¶”ê¸°**: ìš”ì²­í•œ ë¬¸ì œ ìˆ˜ê°€ í™€ìˆ˜ë©´ ì§ìˆ˜ë¡œ ë§ì¶°ì„œ ìƒì„± (ì„¸íŠ¸ ë‹¨ìœ„)
5. **ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´**: ì„¸íŠ¸í˜• ë¬¸ì œëŠ” 6~10í„´ ì •ë„ì˜ ê¸´ ëŒ€í™” ë˜ëŠ” ë‹´í™”
` : ''}

${params.listeningQuestionType === '5-8' ? `
âš ï¸ [1-3ë²ˆ ê·¸ë¦¼ ë¬¸ì œ] í•„ìˆ˜ ì§€ì¹¨ - TOPIK II ì‹¤ì œ ì‹œí—˜ í˜•ì‹ ì¤€ìˆ˜!

TOPIK II ë“£ê¸° ì˜ì—­ì—ì„œ ê·¸ë¦¼ ë¬¸ì œëŠ” **3ë¬¸í•­**ì´ ì¶œì œë©ë‹ˆë‹¤:

## ğŸ“Œ ë¬¸í•­ë³„ ìœ í˜• (ë§¤ìš° ì¤‘ìš”!)

### ë¬¸í•­ 1-2: ì¥ë©´/í–‰ë™ ê·¸ë¦¼ (picture_type: "scene")
- **í˜•ì‹**: ì§§ì€ ëŒ€í™”ë¥¼ ë“£ê³  4ê°œ ê·¸ë¦¼ ì¤‘ ì•Œë§ì€ ê²ƒ ì„ íƒ
- **ê·¸ë¦¼ ìŠ¤íƒ€ì¼**: ë§Œí™”/ì¼ëŸ¬ìŠ¤íŠ¸, êµìœ¡ìš© í‘ë°± ìŠ¤íƒ€ì¼
- **ëŒ€í™” íŠ¹ì§•**: 
  - 2ì¸ ëŒ€í™” (ë‚¨ì-ì—¬ì)
  - 2-3í„´ì˜ ì§§ì€ ëŒ€í™”
  - ì¼ìƒ ìƒí™© (ê³¼ì¼ ê°€ê²Œ, ê°€êµ¬ ë§Œë“¤ê¸° ë“±)
- **listening_script ì˜ˆì‹œ**:
  \`\`\`
  ì—¬ì: ì†ë‹˜, ìˆ˜ë°• ë³´ê³  ê°€ì„¸ìš”. ì•„ì£¼ ë§›ìˆì–´ìš”.
  ë‚¨ì: ì—¬ê¸° ì ‘ì‹œ ìœ„ì— ìˆëŠ” ê±° í•œë²ˆ ë¨¹ì–´ ë´ë„ ë¼ìš”?
  ì—¬ì: ê·¸ëŸ¼ìš”. ë“œì…” ë³´ì„¸ìš”.
  \`\`\`
- **option_image_descriptions ì˜ˆì‹œ**:
  - â‘  "ê³¼ì¼ ê°€ê²Œì—ì„œ ì—¬ì íŒë§¤ì›ì´ ë‚¨ìì—ê²Œ ìˆ˜ë°• ì¡°ê°ì„ ê±´ë„¤ê³ , ë‚¨ìê°€ ë§›ë³´ëŠ” ì¥ë©´"
  - â‘¡ "ë‚¨ìê°€ ìˆ˜ë°•ì„ ë“¤ê³  ê³„ì‚°ëŒ€ë¡œ ê°€ëŠ” ì¥ë©´"
  - â‘¢ "ì—¬ìê°€ ìˆ˜ë°•ì„ ìë¥´ê³  ìˆê³  ë‚¨ìê°€ ì§€ì¼œë³´ëŠ” ì¥ë©´"
  - â‘£ "ë‚¨ìê°€ ìˆ˜ë°•ì„ ë¹„ë‹ë´‰ì§€ì— ë‹´ëŠ” ì¥ë©´"

### ë¬¸í•­ 3: ê·¸ë˜í”„/ë„í‘œ ê·¸ë¦¼ (picture_type: "graph")
- **í˜•ì‹**: ë‹´í™”(ë‰´ìŠ¤, ë³´ë„)ë¥¼ ë“£ê³  4ê°œ ê·¸ë˜í”„/ë„í‘œ ì¤‘ ì•Œë§ì€ ê²ƒ ì„ íƒ
- **ê·¸ë¦¼ ìŠ¤íƒ€ì¼**: ì„  ê·¸ë˜í”„ + ì›í˜•(ë„ë„›) ì°¨íŠ¸ ì¡°í•©
- **ë‹´í™” íŠ¹ì§•**:
  - 1ì¸ ë‹´í™” (ë‰´ìŠ¤ ì•µì»¤, ë¦¬í¬í„°)
  - í†µê³„ ë°ì´í„° ì–¸ê¸‰ (ì—°ë„ë³„ ì¶”ì´, ë¹„ìœ¨ ë“±)
  - ê³µì‹ì  ì–´íˆ¬
- **listening_script ì˜ˆì‹œ**:
  \`\`\`
  ë‚¨ì: ì±„ì†Œ, ë‹¬ê±€ ë“±ì˜ ì‹í’ˆì„ ì •ê¸°ì ìœ¼ë¡œ ë°°ë‹¬ ë°›ëŠ” ì„œë¹„ìŠ¤ê°€ ì¸ê¸°ë¥¼ ëŒë©° ìµœê·¼ 4ë…„ê°„ ì´ìš©ìê°€ ê¾¸ì¤€íˆ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ëŠ” ì´ìœ ë¡œëŠ” 'ì‹ ì„ í•˜ê³  í’ˆì§ˆì´ ì¢‹ì•„ì„œ'ê°€ ê°€ì¥ ë§ì•˜ìœ¼ë©°, 'ê°€ê²©ì´ í•©ë¦¬ì ì´ì–´ì„œ', 'í¸ë¦¬í•´ì„œ'ê°€ ê·¸ ë’¤ë¥¼ ì´ì—ˆìŠµë‹ˆë‹¤.
  \`\`\`
- **option_image_descriptions ì˜ˆì‹œ** (4ê°œ ëª¨ë‘ ë‹¤ë¥¸ ë°ì´í„° ì¡°í•©):
  - â‘  "ì„ ê·¸ë˜í”„: 2020ë…„ 3ë§Œëª… â†’ 2021ë…„ 6ë§Œëª… â†’ 2022ë…„ 9ë§Œëª… â†’ 2023ë…„ 12ë§Œëª… (ê¾¸ì¤€íˆ ì¦ê°€). ì›ì°¨íŠ¸: ì‹ ì„ /í’ˆì§ˆ 43%, í¸ë¦¬ 36%, ê°€ê²© 21%"
  - â‘¡ "ì„ ê·¸ë˜í”„: 2020ë…„ 12ë§Œëª… â†’ 2021ë…„ 9ë§Œëª… â†’ 2022ë…„ 6ë§Œëª… â†’ 2023ë…„ 12ë§Œëª… (Vì í˜•íƒœ). ì›ì°¨íŠ¸: ë™ì¼"
  - â‘¢ "ì„ ê·¸ë˜í”„: ê¾¸ì¤€íˆ ì¦ê°€. ì›ì°¨íŠ¸: ê°€ê²© 43%, í’ˆì§ˆ 21%, í¸ë¦¬ 36% (ìˆœì„œ ë‹¤ë¦„)"
  - â‘£ "ì„ ê·¸ë˜í”„: ê¾¸ì¤€íˆ ì¦ê°€. ì›ì°¨íŠ¸: í’ˆì§ˆ 21%, í¸ë¦¬ 36%, ê°€ê²© 43% (ë¹„ìœ¨ ë‹¤ë¦„)"

## âš ï¸ í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­

1. **question_number 1, 2**: picture_type="scene", ëŒ€í™”í˜• ìŠ¤í¬ë¦½íŠ¸
2. **question_number 3**: picture_type="graph", ë‹´í™”í˜• ìŠ¤í¬ë¦½íŠ¸
3. **options í•„ë“œ**: ["â‘ ", "â‘¡", "â‘¢", "â‘£"]ë¡œ ê³ ì •
4. **option_image_descriptions**: ì •ë‹µ ë²ˆí˜¸ì— í•´ë‹¹í•˜ëŠ” ì„¤ëª…ë§Œ ìŠ¤í¬ë¦½íŠ¸ì™€ ì™„ì „íˆ ì¼ì¹˜
5. **ì˜¤ë‹µ 3ê°œ**: ë¹„ìŠ·í•˜ì§€ë§Œ í•µì‹¬ ìš”ì†Œ(í–‰ë™/ìœ„ì¹˜/ìˆ˜ì¹˜/ë¹„ìœ¨)ê°€ ë‹¤ë¥´ê²Œ ì„¤ê³„
` : ''}
ëª¨ë“  í•„ë“œë¥¼ ë°˜ë“œì‹œ ì±„ìš°ì„¸ìš”. ë¹ˆ ê°’ì´ ìˆìœ¼ë©´ ì•ˆ ë©ë‹ˆë‹¤.`;

  return prompt;
}

// Streaming handler
async function handleStreamingGeneration(
  params: GenerateRequest,
  ragContext: string,
  supabase: any
): Promise<Response> {
  const encoder = new TextEncoder();
  const systemPrompt = buildSystemPrompt(params, ragContext);
  
  // ë“£ê¸° ë¬¸ì œëŠ” Claude ì‚¬ìš©, ë‚˜ë¨¸ì§€ëŠ” Gemini 2.5 Pro
  const useClaude = params.section === 'listening';
  const modelName = useClaude ? 'claude-sonnet-4-5-20250929' : (Deno.env.get("GEMINI_MODEL") || "gemini-2.5-pro");

  const stream = new ReadableStream({
    async start(controller) {
      try {
        // Send progress update
        const sendProgress = (step: string, progress: number, message: string) => {
          const data = JSON.stringify({ type: "progress", step, progress, message });
          controller.enqueue(encoder.encode(`data: ${data}\n\n`));
        };

        sendProgress("rag", 20, "ğŸ“š RAG ê²€ìƒ‰ ì™„ë£Œ");
        
        const modelLabel = useClaude ? "Claude Sonnet 4 (ë“£ê¸° ì „ìš©)" : "Gemini 2.5 Pro";
        sendProgress("generating", 30, `ğŸ¤– ${modelLabel} ë¬¸ì œ ìƒì„± ì‹œì‘...`);

        let aiResponse: Response | null = null;
        let lastError = "";
        
        // ìµœëŒ€ 10ë¶„ (600ì´ˆ) íƒ€ì„ì•„ì›ƒ - ë“£ê¸° ë¬¸ì œ ìƒì„± ì‹œ TTSê¹Œì§€ í¬í•¨
        const AI_TIMEOUT_MS = 600000; // 10 minutes
        
        const userPrompt = `${systemPrompt}\n\n---\n\n${params.questionCount}ê°œì˜ ${params.section} ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
${params.topic ? `ì£¼ì œ/ë¬¸ë²•: ${params.topic}` : ''}
ë‚œì´ë„: ${params.difficulty}
ëª¨ë“  ë¬¸ì œëŠ” ì‹¤ì œ TOPIK ì‹œí—˜ê³¼ ë™ì¼í•œ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.`;
        
        for (let attempt = 0; attempt < 3; attempt++) {
          try {
            const abortController = new AbortController();
            const timeoutId = setTimeout(() => abortController.abort(), AI_TIMEOUT_MS);
            
            sendProgress("generating", 30 + attempt * 2, `ğŸ¤– ${modelLabel} í˜¸ì¶œ ì¤‘... (ì‹œë„ ${attempt + 1}/3, ìµœëŒ€ 10ë¶„)`);
            
            if (useClaude) {
              // Claude API í˜¸ì¶œ (ë“£ê¸° ë¬¸ì œìš©) - ìŠ¤íŠ¸ë¦¬ë°
              console.log(`ğŸ§ Using Claude Sonnet 4 for listening questions`);
              aiResponse = await fetch('https://api.anthropic.com/v1/messages', {
                method: 'POST',
                headers: {
                  'x-api-key': ANTHROPIC_API_KEY!,
                  'anthropic-version': '2023-06-01',
                  'Content-Type': 'application/json',
                },
                signal: abortController.signal,
                body: JSON.stringify({
                  model: 'claude-sonnet-4-5-20250929',
                  max_tokens: 16384,
                  stream: true,
                  system: 'You are a TOPIK exam question generator. Always respond in valid JSON format with a "questions" array. Output only JSON, no other text.',
                  messages: [
                    { role: 'user', content: userPrompt }
                  ],
                }),
              });
            } else {
              // Gemini API í˜¸ì¶œ (ì½ê¸°/ì“°ê¸° ë¬¸ì œìš©)
              aiResponse = await fetch(
                `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:streamGenerateContent?key=${GEMINI_API_KEY}&alt=sse`,
                {
                  method: "POST",
                  headers: { "Content-Type": "application/json" },
                  signal: abortController.signal,
                  body: JSON.stringify({
                    contents: [{
                      role: "user",
                      parts: [{ text: userPrompt }]
                    }],
                    generationConfig: {
                      temperature: 0.7,
                      topP: 0.95,
                      topK: 40,
                      maxOutputTokens: 65536,
                      responseMimeType: "application/json",
                      thinkingConfig: {
                        thinkingBudget: 24576,
                      },
                    },
                    safetySettings: [
                      { category: "HARM_CATEGORY_HARASSMENT", threshold: "BLOCK_NONE" },
                      { category: "HARM_CATEGORY_HATE_SPEECH", threshold: "BLOCK_NONE" },
                      { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_NONE" },
                      { category: "HARM_CATEGORY_DANGEROUS_CONTENT", threshold: "BLOCK_NONE" },
                    ],
                  }),
                }
              );
            }
            
            clearTimeout(timeoutId);

            if (aiResponse.ok) break;
            
            const errorText = await aiResponse.text();
            lastError = `API error: ${aiResponse.status}`;
            console.error(`${modelLabel} attempt ${attempt + 1} failed:`, aiResponse.status, errorText.slice(0, 200));
            
            // Retry on 503 (overloaded) or 429 (rate limit)
            if (aiResponse.status === 503 || aiResponse.status === 429) {
              sendProgress("generating", 32, `â³ ì¬ì‹œë„ ì¤‘... (${attempt + 1}/3)`);
              await new Promise(r => setTimeout(r, 3000 * (attempt + 1))); // Exponential backoff
            } else {
              break; // Don't retry other errors
            }
          } catch (fetchError: any) {
            if (fetchError.name === 'AbortError') {
              lastError = `íƒ€ì„ì•„ì›ƒ (10ë¶„ ì´ˆê³¼) - ë¬¸ì œ ìˆ˜ë¥¼ ì¤„ì—¬ì„œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`;
              console.error(`${modelLabel} timeout after ${AI_TIMEOUT_MS}ms on attempt ${attempt + 1}`);
            } else {
              lastError = fetchError.message || "Network error";
              console.error(`${modelLabel} fetch error attempt ${attempt + 1}:`, lastError);
            }
            if (attempt < 2) {
              await new Promise(r => setTimeout(r, 3000 * (attempt + 1)));
            }
          }
        }

        if (!aiResponse || !aiResponse.ok) {
          throw new Error(lastError || "AI API í˜¸ì¶œ ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        }

        // Stream the response
        const reader = aiResponse.body?.getReader();
        if (!reader) throw new Error("No response body");

        let fullContent = "";
        let chunkCount = 0;
        const decoder = new TextDecoder();

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value, { stream: true });
          const lines = chunk.split('\n');

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              try {
                const jsonStr = line.slice(6);
                if (jsonStr.trim() === '[DONE]') continue;
                
                const parsed = JSON.parse(jsonStr);
                
                // Claudeì™€ Geminiì˜ ì‘ë‹µ í˜•ì‹ì´ ë‹¤ë¦„
                let text = '';
                if (useClaude) {
                  // Anthropic Claude ìŠ¤íŠ¸ë¦¬ë° í˜•ì‹
                  if (parsed.type === 'content_block_delta' && parsed.delta?.type === 'text_delta') {
                    text = parsed.delta.text || '';
                  }
                } else {
                  // Gemini ìŠ¤íŠ¸ë¦¬ë° í˜•ì‹
                  text = parsed.candidates?.[0]?.content?.parts?.[0]?.text || '';
                }
                
                if (text) {
                  fullContent += text;
                  chunkCount++;
                  
                  // Send token chunk to client
                  const tokenData = JSON.stringify({ type: "token", content: text, count: chunkCount });
                  controller.enqueue(encoder.encode(`data: ${tokenData}\n\n`));
                  
                  // Update progress periodically
                  if (chunkCount % 20 === 0) {
                    const progress = Math.min(30 + (chunkCount / 5), 80);
                    sendProgress("generating", progress, `ğŸ¤– ìƒì„± ì¤‘... (${chunkCount} í† í°)`);
                  }
                }
              } catch (e) {
                // Ignore parse errors for partial chunks
              }
            } else if (line.startsWith('event: ')) {
              // Claude SSE event ì²˜ë¦¬
              continue;
            }
          }
        }

        sendProgress("parsing", 85, "ğŸ“ ìƒì„±ëœ ë¬¸ì œ íŒŒì‹± ì¤‘...");

        // Parse the complete content
        let parsed: { questions: GeneratedQuestion[] };
        try {
          let jsonContent = fullContent;
          if (jsonContent.startsWith("```json")) jsonContent = jsonContent.slice(7);
          if (jsonContent.startsWith("```")) jsonContent = jsonContent.slice(3);
          if (jsonContent.endsWith("```")) jsonContent = jsonContent.slice(0, -3);
          parsed = JSON.parse(jsonContent.trim());
        } catch (e) {
          console.error("Failed to parse AI response:", fullContent.slice(0, 500));
          throw new Error("Failed to parse AI response as JSON");
        }

        // Validate questions
        let validQuestions = (parsed.questions || []).filter((q) => {
          return (
            q.question_text &&
            Array.isArray(q.options) &&
            q.options.length >= 4 &&
            typeof q.correct_answer === "number" &&
            q.correct_answer >= 1 &&
            q.correct_answer <= 4 &&
            q.explanation_ko
          );
        });

        sendProgress("audio", 88, `âœ… ${validQuestions.length}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ`);

        // Generate 4 images for picture dialogue questions [5-8]
        // TOPIK II: ë¬¸í•­ 1-2ëŠ” ì¥ë©´ ê·¸ë¦¼(scene), ë¬¸í•­ 3ì€ ê·¸ë˜í”„(graph)
        if (params.section === 'listening' && params.listeningQuestionType === '5-8') {
          sendProgress("image", 89, "ğŸ–¼ï¸ ê·¸ë¦¼ ë¬¸ì œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...");
          
          for (let i = 0; i < validQuestions.length; i++) {
            const q = validQuestions[i];
            if (q.option_image_descriptions && q.option_image_descriptions.length === 4) {
              const optionImages: string[] = [];
              const questionNum = q.question_number || i + 1;
              
              let pictureType: PictureQuestionType;
              if (q.picture_type === "graph" || q.picture_type === "scene") {
                pictureType = q.picture_type;
              } else {
                pictureType = (questionNum === 3) ? "graph" : "scene";
              }
              const typeLabel = pictureType === "graph" ? "ğŸ“Š ê·¸ë˜í”„" : "ğŸ¨ ì¥ë©´";
              
              console.log(`[Q${questionNum}] Picture type: ${pictureType}`);
              
              for (let j = 0; j < 4; j++) {
                const desc = q.option_image_descriptions[j];
                sendProgress("image", 89 + ((i * 4 + j) / (validQuestions.length * 4)) * 3, 
                  `${typeLabel} Q${questionNum} ë³´ê¸° ${j + 1} ìƒì„± ì¤‘...`);
                
                const imageUrl = await generatePictureQuestionImage(
                  desc,
                  questionNum,
                  j + 1,
                  pictureType,
                  params.examType,
                  supabase
                );
                optionImages.push(imageUrl || '');
              }
              
              validQuestions[i].option_images = optionImages;
            }
          }
        }

        // Generate audio for listening questions
        if (params.section === 'listening' && params.generateAudio !== false && GEMINI_API_KEY) {
          sendProgress("audio", 92, "ğŸµ TTS ìŒì„± ìƒì„± ì¤‘...");
          
          const ttsPreset = params.ttsPreset || 'exam';
          
          for (let i = 0; i < validQuestions.length; i++) {
            const q = validQuestions[i];
            if (q.listening_script) {
              sendProgress("audio", 92 + (i / validQuestions.length) * 6, `ğŸµ Q${i + 1} ìŒì„± ìƒì„± ì¤‘...`);
              
              const audioUrl = await generateListeningAudio(
                q.listening_script,
                q.question_number || i + 1,
                params.examType,
                supabase,
                ttsPreset
              );
              if (audioUrl) {
                validQuestions[i].question_audio_url = audioUrl;
              }
            }
          }
        }

        sendProgress("complete", 100, "ğŸ‰ ìƒì„± ì™„ë£Œ!");

        // Send final result
        const finalData = JSON.stringify({
          type: "complete",
          success: true,
          questions: validQuestions,
          ragUsed: !!ragContext,
          ragDocCount: ragContext ? ragContext.split('---').length : 0,
          model: modelName,
        });
        controller.enqueue(encoder.encode(`data: ${finalData}\n\n`));
        controller.close();

      } catch (error: any) {
        console.error("Streaming error:", error);
        const errorData = JSON.stringify({ type: "error", error: error.message });
        controller.enqueue(encoder.encode(`data: ${errorData}\n\n`));
        controller.close();
      }
    },
  });

  return new Response(stream, {
    headers: {
      ...corsHeaders,
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      "Connection": "keep-alive",
    },
  });
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const params: GenerateRequest = await req.json();
    
    console.log("ğŸ¯ Mock Exam Generation Request:", {
      examType: params.examType,
      section: params.section,
      difficulty: params.difficulty,
      topic: params.topic,
      questionCount: params.questionCount,
      useRag: params.useRag,
      generateAudio: params.generateAudio,
      ttsPreset: params.ttsPreset,
      stream: params.stream,
      hasReference: !!params.referenceDocContent,
      // ë“£ê¸° ì„¸ë¶€ ì„¤ì •
      listeningQuestionType: params.listeningQuestionType,
      dialogueLength: params.dialogueLength,
      speakerCount: params.speakerCount,
    });

    if (!GEMINI_API_KEY) {
      throw new Error("GEMINI_API_KEY not configured");
    }

    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseServiceKey);

    // RAG Search for context - Enhanced for listening section
    let ragContext = '';
    if (params.useRag !== false && OPENAI_API_KEY) {
      const searchQuery = `TOPIK ${params.examType === 'topik1' ? 'I' : 'II'} ${params.section} ${params.difficulty} ${params.topic || ''}`.trim();
      ragContext = await ragSearch(searchQuery, supabase, params.section, params.difficulty);
    }

    // Handle streaming mode
    if (params.stream) {
      return handleStreamingGeneration(params, ragContext, supabase);
    }

    // Non-streaming mode (legacy)
    const systemPrompt = buildSystemPrompt(params, ragContext);
    const geminiModel = Deno.env.get("GEMINI_MODEL") || "gemini-2.5-pro";

    console.log("ğŸ¤– Calling Gemini 2.5 Pro directly...");
    
    const geminiResponse = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${geminiModel}:generateContent?key=${GEMINI_API_KEY}`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{
            role: "user",
            parts: [{
              text: `${systemPrompt}\n\n---\n\n${params.questionCount}ê°œì˜ ${params.section} ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
${params.topic ? `ì£¼ì œ/ë¬¸ë²•: ${params.topic}` : ''}
ë‚œì´ë„: ${params.difficulty}
ëª¨ë“  ë¬¸ì œëŠ” ì‹¤ì œ TOPIK ì‹œí—˜ê³¼ ë™ì¼í•œ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.`
            }]
          }],
          generationConfig: {
            temperature: 0.7,
            topP: 0.95,
            topK: 40,
            maxOutputTokens: 65536,
            responseMimeType: "application/json",
          },
          safetySettings: [
            { category: "HARM_CATEGORY_HARASSMENT", threshold: "BLOCK_NONE" },
            { category: "HARM_CATEGORY_HATE_SPEECH", threshold: "BLOCK_NONE" },
            { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_NONE" },
            { category: "HARM_CATEGORY_DANGEROUS_CONTENT", threshold: "BLOCK_NONE" },
          ],
        }),
      }
    );

    if (!geminiResponse.ok) {
      const errorText = await geminiResponse.text();
      console.error("Gemini API error:", geminiResponse.status, errorText);
      throw new Error(`Gemini API error: ${geminiResponse.status} - ${errorText}`);
    }

    const geminiData = await geminiResponse.json();
    const content = geminiData.candidates?.[0]?.content?.parts?.[0]?.text;
    
    if (!content) {
      throw new Error("No content in Gemini response");
    }

    let parsed: { questions: GeneratedQuestion[] };
    try {
      let jsonContent = content;
      if (jsonContent.startsWith("```json")) jsonContent = jsonContent.slice(7);
      if (jsonContent.startsWith("```")) jsonContent = jsonContent.slice(3);
      if (jsonContent.endsWith("```")) jsonContent = jsonContent.slice(0, -3);
      parsed = JSON.parse(jsonContent.trim());
    } catch (e) {
      console.error("Failed to parse Gemini response:", content);
      throw new Error("Failed to parse Gemini response as JSON");
    }

    let validQuestions = (parsed.questions || []).filter((q) => {
      return (
        q.question_text &&
        Array.isArray(q.options) &&
        q.options.length >= 4 &&
        typeof q.correct_answer === "number" &&
        q.correct_answer >= 1 &&
        q.correct_answer <= 4 &&
        q.explanation_ko
      );
    });

    console.log(`âœ… Generated ${validQuestions.length} valid questions`);

    // Generate audio for listening questions
    if (params.section === 'listening' && params.generateAudio !== false && GEMINI_API_KEY) {
      const ttsPreset = params.ttsPreset || 'exam';
      
      for (let i = 0; i < validQuestions.length; i++) {
        const q = validQuestions[i];
        if (q.listening_script) {
          const audioUrl = await generateListeningAudio(
            q.listening_script,
            q.question_number || i + 1,
            params.examType,
            supabase,
            ttsPreset
          );
          if (audioUrl) {
            validQuestions[i].question_audio_url = audioUrl;
          }
        }
      }
    }

    return new Response(
      JSON.stringify({
        success: true,
        questions: validQuestions,
        ragUsed: !!ragContext,
        ragDocCount: ragContext ? ragContext.split('---').length : 0,
        model: geminiModel,
      }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );

  } catch (error: unknown) {
    console.error("Generation error:", error);
    const errorMessage = error instanceof Error ? error.message : "Unknown error";
    return new Response(
      JSON.stringify({ error: errorMessage }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});
